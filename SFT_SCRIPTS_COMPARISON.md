# SFT è„šæœ¬å¯¹æ¯”ï¼šfinetune_lora.sh vs finetune_lora_med.sh

## ğŸ“‹ å¿«é€Ÿå¯¹æ¯”è¡¨

| ç‰¹æ€§ | `finetune_lora.sh` | `finetune_lora_med.sh` |
|------|-------------------|------------------------|
| **ç”¨é€”** | é€šç”¨ç¯å¢ƒ (Sokoban, FrozenLake) | åŒ»ç–—å¯¹è¯ (DoctorAgent-RL) |
| **è¾“å…¥å‚æ•°** | `[env_type] <nproc> <save_path>` | `<nproc> <save_path>` |
| **é»˜è®¤ç¯å¢ƒ** | sokoban (å¯é…ç½®) | medical_consultation (å›ºå®š) |
| **è®­ç»ƒæ•°æ®** | `data/sft/${env_type}/train.parquet` | `data/MTMedDialog_sft_train.parquet` |
| **éªŒè¯æ•°æ®** | `data/sft/${env_type}/test.parquet` | `data/MTMedDialog_sft_val.parquet` |
| **åŸºç¡€æ¨¡å‹** | Qwen2.5-0.5B | Qwen2.5-7B-Instruct |
| **max_length** | 2048 | 6784 |
| **micro_batch_size** | 4 | 8 |
| **total_epochs** | 5 | 3 |
| **gradient_checkpointing** | False | True |
| **with_thinking** | æœªè®¾ç½® | False (å¯é…ç½®) |
| **è‡ªåŠ¨åˆå¹¶ LoRA** | âŒ å¦ | âœ… æ˜¯ |
| **é¡¹ç›®åç§°** | æœªè®¾ç½® | Medical-Dialogue |

---

## ğŸ” é€è¡Œå¯¹æ¯”

### **1. å‚æ•°è§£æ**

#### `finetune_lora.sh`
```bash
env_type=${1:-sokoban}  # ç¬¬ä¸€ä¸ªå‚æ•°æ˜¯ç¯å¢ƒç±»å‹ï¼Œé»˜è®¤ sokoban
shift 1
nproc_per_node=$1       # ç¬¬äºŒä¸ªå‚æ•°æ˜¯ GPU æ•°é‡
save_path=$2            # ç¬¬ä¸‰ä¸ªå‚æ•°æ˜¯ä¿å­˜è·¯å¾„
```

**ä½¿ç”¨ç¤ºä¾‹ï¼š**
```bash
bash sft/finetune_lora.sh sokoban 4 ./sft_output
bash sft/finetune_lora.sh frozenlake 8 ./sft_output
```

#### `finetune_lora_med.sh`
```bash
nproc_per_node=$1       # ç¬¬ä¸€ä¸ªå‚æ•°æ˜¯ GPU æ•°é‡
save_path=$2            # ç¬¬äºŒä¸ªå‚æ•°æ˜¯ä¿å­˜è·¯å¾„
# ç¯å¢ƒå›ºå®šä¸ºåŒ»ç–—å¯¹è¯ï¼Œæ— éœ€æŒ‡å®š
```

**ä½¿ç”¨ç¤ºä¾‹ï¼š**
```bash
bash sft/finetune_lora_med.sh 8 ./sft_output
```

---

### **2. æ•°æ®é…ç½®**

#### `finetune_lora.sh` (é€šç”¨ç¯å¢ƒ)
```bash
data.train_files=data/sft/${env_type}/train.parquet
data.val_files=data/sft/${env_type}/test.parquet
data.max_length=2048
```

**æ•°æ®è·¯å¾„ç¤ºä¾‹ï¼š**
- Sokoban: `data/sft/sokoban/train.parquet`
- FrozenLake: `data/sft/frozenlake/train.parquet`

#### `finetune_lora_med.sh` (åŒ»ç–—å¯¹è¯)
```bash
data.train_files=data/MTMedDialog_sft_train.parquet
data.val_files=data/MTMedDialog_sft_val.parquet
data.max_length=6784
```

**ä¸ºä»€ä¹ˆ max_length ä¸åŒï¼Ÿ**
- **é€šç”¨ç¯å¢ƒ (2048)**: æ¸¸æˆç¯å¢ƒçš„å¯¹è¯è¾ƒçŸ­ï¼Œ2048 è¶³å¤Ÿ
- **åŒ»ç–—å¯¹è¯ (6784)**: åŒ»ç–—å’¨è¯¢åŒ…å«é•¿å¯¹è¯å†å² + æ€è€ƒè¿‡ç¨‹ï¼Œéœ€è¦æ›´é•¿çš„ä¸Šä¸‹æ–‡

---

### **3. æ¨¡å‹é…ç½®**

#### `finetune_lora.sh` (è½»é‡æ¨¡å‹)
```bash
model.partial_pretrain=Qwen/Qwen2.5-0.5B
model.enable_gradient_checkpointing=False
data.micro_batch_size=4
```

**ç‰¹ç‚¹ï¼š**
- âœ… 0.5B å°æ¨¡å‹ï¼Œè®­ç»ƒå¿«ï¼Œæ˜¾å­˜å ç”¨å°‘
- âœ… ä¸ç”¨ gradient checkpointingï¼ˆé€Ÿåº¦ä¼˜å…ˆï¼‰
- âœ… é€‚åˆå¿«é€Ÿå®éªŒå’Œè°ƒè¯•

#### `finetune_lora_med.sh` (ç”Ÿäº§çº§æ¨¡å‹)
```bash
model.partial_pretrain=Qwen2.5-7B-Instruct
model.enable_gradient_checkpointing=True
data.micro_batch_size=8
```

**ç‰¹ç‚¹ï¼š**
- âœ… 7B å¤§æ¨¡å‹ï¼Œæ€§èƒ½æ›´å¼º
- âœ… å¯ç”¨ gradient checkpointingï¼ˆèŠ‚çœæ˜¾å­˜ï¼‰
- âœ… æ›´å¤§çš„ micro_batch_sizeï¼ˆæ›´ç¨³å®šçš„æ¢¯åº¦ï¼‰
- âœ… é€‚åˆç”Ÿäº§ç¯å¢ƒéƒ¨ç½²

---

### **4. è®­ç»ƒè¶…å‚æ•°**

#### `finetune_lora.sh`
```bash
data.train_batch_size=128
data.micro_batch_size=4
trainer.total_epochs=5
optim.lr=1e-4
```

**æ¢¯åº¦ç´¯ç§¯æ­¥æ•°ï¼š**
```
gradient_accumulation_steps = train_batch_size / (micro_batch_size Ã— n_gpus)
                            = 128 / (4 Ã— 4)  # å‡è®¾ 4 GPUs
                            = 8
```

#### `finetune_lora_med.sh`
```bash
data.train_batch_size=128
data.micro_batch_size=8
trainer.total_epochs=3
optim.lr=1e-4
```

**æ¢¯åº¦ç´¯ç§¯æ­¥æ•°ï¼š**
```
gradient_accumulation_steps = 128 / (8 Ã— 8)  # å‡è®¾ 8 GPUs
                            = 2
```

**ä¸ºä»€ä¹ˆ epochs ä¸åŒï¼Ÿ**
- **é€šç”¨ç¯å¢ƒ (5 epochs)**: æ•°æ®é‡è¾ƒå°ï¼Œéœ€è¦æ›´å¤šè½®æ¬¡
- **åŒ»ç–—å¯¹è¯ (3 epochs)**: æ•°æ®é›†è¾ƒå¤§ï¼Œ3 è½®è¶³å¤Ÿï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ

---

### **5. ç‰¹æ®ŠåŠŸèƒ½**

#### `finetune_lora.sh`
```bash
# è®­ç»ƒå®Œæˆåä¸è‡ªåŠ¨åˆå¹¶ LoRA
# éœ€è¦æ‰‹åŠ¨è¿è¡Œï¼š
python sft/utils/merge_lora.py \
    --base_model_name Qwen/Qwen2.5-0.5B \
    --lora_model_path ./sft_output \
    --output_path merged_model
```

#### `finetune_lora_med.sh`
```bash
# è®­ç»ƒå®Œæˆåè‡ªåŠ¨åˆå¹¶ LoRA
python sft/utils/merge_lora.py \
    --base_model_name Qwen2.5-7B-Instruct \
    --lora_model_path $save_path \
    --output_path DoctorLLM-7B-SFT-1000-thinking
```

**åŒºåˆ«ï¼š**
- âœ… `finetune_lora_med.sh` è‡ªåŠ¨åˆå¹¶ï¼Œç›´æ¥å¾—åˆ°å¯ç”¨æ¨¡å‹
- âŒ `finetune_lora.sh` éœ€è¦æ‰‹åŠ¨åˆå¹¶ï¼ˆæ›´çµæ´»ï¼‰

---

### **6. åŒ»ç–—å¯¹è¯ç‰¹æœ‰å‚æ•°**

#### `finetune_lora_med.sh` ç‹¬æœ‰
```bash
+data.with_thinking=False
trainer.project_name=Medical-Dialogue
```

**`with_thinking` å‚æ•°è¯´æ˜ï¼š**
- `True`: è®­ç»ƒæ—¶ä¿ç•™ `<think>...</think>` æ ‡ç­¾
- `False`: è®­ç»ƒæ—¶å»é™¤æ€è€ƒæ ‡ç­¾ï¼Œåªè®­ç»ƒæœ€ç»ˆå›ç­”

**æ•°æ®æ ¼å¼ç¤ºä¾‹ï¼š**
```python
# with_thinking=True (ä¿ç•™æ€è€ƒè¿‡ç¨‹)
response = "<think>æ‚£è€…å¯èƒ½æœ‰æ¶ˆåŒ–é—®é¢˜ï¼Œéœ€è¦è¯¢é—®é¥®é£Ÿ</think><answer>è¯·é—®æ‚¨æœ€è¿‘çš„é¥®é£Ÿä¹ æƒ¯å¦‚ä½•ï¼Ÿ</answer>"

# with_thinking=False (åªä¿ç•™å›ç­”)
response = "è¯·é—®æ‚¨æœ€è¿‘çš„é¥®é£Ÿä¹ æƒ¯å¦‚ä½•ï¼Ÿ"
```

---

## ğŸ¯ ä½¿ç”¨åœºæ™¯é€‰æ‹©

### **ä½¿ç”¨ `finetune_lora.sh`** çš„æƒ…å†µ

âœ… **é€‚åˆï¼š**
- è®­ç»ƒ Sokoban / FrozenLake ç­‰æ¸¸æˆç¯å¢ƒ
- å¿«é€ŸåŸå‹å¼€å‘å’Œå®éªŒ
- æ˜¾å­˜å—é™ï¼ˆä½¿ç”¨å°æ¨¡å‹ï¼‰
- éœ€è¦çµæ´»é…ç½®ç¯å¢ƒç±»å‹

âŒ **ä¸é€‚åˆï¼š**
- åŒ»ç–—å¯¹è¯ç­‰å¤æ‚ä»»åŠ¡
- éœ€è¦é•¿ä¸Šä¸‹æ–‡çš„ä»»åŠ¡
- ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²

**ä½¿ç”¨ç¤ºä¾‹ï¼š**
```bash
# Sokoban SFT
bash sft/finetune_lora.sh sokoban 4 ./sft_sokoban

# FrozenLake SFT
bash sft/finetune_lora.sh frozenlake 4 ./sft_frozenlake
```

---

### **ä½¿ç”¨ `finetune_lora_med.sh`** çš„æƒ…å†µ

âœ… **é€‚åˆï¼š**
- DoctorAgent-RL é¡¹ç›®çš„ SFT cold start
- åŒ»ç–—å¯¹è¯ç­‰å¤æ‚ä»»åŠ¡
- éœ€è¦å¤§æ¨¡å‹æ€§èƒ½
- éœ€è¦è‡ªåŠ¨åŒ–æµç¨‹ï¼ˆè®­ç»ƒ+åˆå¹¶ï¼‰

âŒ **ä¸é€‚åˆï¼š**
- å¿«é€Ÿå®éªŒï¼ˆ7B æ¨¡å‹è®­ç»ƒè¾ƒæ…¢ï¼‰
- æ˜¾å­˜å—é™çš„æœºå™¨
- éåŒ»ç–—å¯¹è¯ä»»åŠ¡

**ä½¿ç”¨ç¤ºä¾‹ï¼š**
```bash
# DoctorAgent-RL SFT
bash sft/finetune_lora_med.sh 8 ./sft_checkpoints

# è®­ç»ƒå®Œæˆåè‡ªåŠ¨ç”Ÿæˆï¼š
# - ./sft_checkpoints/global_step_*/  (LoRA æƒé‡)
# - DoctorLLM-7B-SFT-1000-thinking/   (åˆå¹¶åçš„æ¨¡å‹)
```

---

## ğŸ“Š èµ„æºéœ€æ±‚å¯¹æ¯”

### **GPU æ˜¾å­˜éœ€æ±‚ï¼ˆä¼°ç®—ï¼‰**

| é…ç½® | `finetune_lora.sh` | `finetune_lora_med.sh` |
|------|-------------------|------------------------|
| **æ¨¡å‹å¤§å°** | 0.5B | 7B |
| **å• GPU æ˜¾å­˜** | ~8 GB | ~24 GB |
| **æ¨è GPU** | RTX 3090 (24GB) | A100 (40GB/80GB) |
| **æœ€å°‘ GPU æ•°** | 1 | 4 |
| **æ¨è GPU æ•°** | 4 | 8 |

### **è®­ç»ƒæ—¶é—´ï¼ˆä¼°ç®—ï¼‰**

| é…ç½® | `finetune_lora.sh` | `finetune_lora_med.sh` |
|------|-------------------|------------------------|
| **æ•°æ®é‡** | ~1000 æ ·æœ¬ | ~1000 æ ·æœ¬ |
| **Epochs** | 5 | 3 |
| **å• epoch æ—¶é—´** | ~5-10 åˆ†é’Ÿ | ~30-60 åˆ†é’Ÿ |
| **æ€»è®­ç»ƒæ—¶é—´** | ~30-50 åˆ†é’Ÿ | ~2-3 å°æ—¶ |

---

## ğŸ”§ ä¿®æ”¹å»ºè®®

### **å¦‚æœä½ æƒ³ç”¨å°æ¨¡å‹æµ‹è¯•åŒ»ç–—å¯¹è¯**

ä¿®æ”¹ `finetune_lora_med.sh`:
```bash
# æ”¹ä¸ºå°æ¨¡å‹
model.partial_pretrain=Qwen/Qwen2.5-0.5B

# å‡å° max_length (é¿å…æ˜¾å­˜æº¢å‡º)
data.max_length=2048

# å¯ä»¥å…³é—­ gradient checkpointing (åŠ é€Ÿ)
model.enable_gradient_checkpointing=False
```

### **å¦‚æœä½ æƒ³ç”¨å¤§æ¨¡å‹è®­ç»ƒ Sokoban**

ä¿®æ”¹ `finetune_lora.sh`:
```bash
# æ”¹ä¸ºå¤§æ¨¡å‹
model.partial_pretrain=Qwen/Qwen2.5-7B-Instruct

# å¯ç”¨ gradient checkpointing
model.enable_gradient_checkpointing=True

# è°ƒæ•´ batch size
data.micro_batch_size=8
```

---

## ğŸ’¡ å…³é”®æ€»ç»“

### **æ ¸å¿ƒåŒºåˆ«**
1. **ç›®æ ‡ä»»åŠ¡ä¸åŒ**:
   - `finetune_lora.sh`: æ¸¸æˆç¯å¢ƒï¼ˆè§„åˆ™ç®€å•ï¼‰
   - `finetune_lora_med.sh`: åŒ»ç–—å¯¹è¯ï¼ˆå¤æ‚æ¨ç†ï¼‰

2. **æ¨¡å‹è§„æ¨¡ä¸åŒ**:
   - `finetune_lora.sh`: 0.5B å°æ¨¡å‹ï¼ˆå¿«é€Ÿå®éªŒï¼‰
   - `finetune_lora_med.sh`: 7B å¤§æ¨¡å‹ï¼ˆç”Ÿäº§çº§ï¼‰

3. **ä¸Šä¸‹æ–‡é•¿åº¦ä¸åŒ**:
   - `finetune_lora.sh`: 2048 tokensï¼ˆæ¸¸æˆçŠ¶æ€ç®€çŸ­ï¼‰
   - `finetune_lora_med.sh`: 6784 tokensï¼ˆåŒ»ç–—å¯¹è¯é•¿ï¼‰

4. **è‡ªåŠ¨åŒ–ç¨‹åº¦ä¸åŒ**:
   - `finetune_lora.sh`: åªè®­ç»ƒï¼Œæ‰‹åŠ¨åˆå¹¶
   - `finetune_lora_med.sh`: è®­ç»ƒ + è‡ªåŠ¨åˆå¹¶

### **åº•å±‚ä¸€è‡´**
- âœ… éƒ½ä½¿ç”¨ `ragen.trainer.fsdp_sft_trainer`
- âœ… éƒ½ä½¿ç”¨ LoRA (rank=64, alpha=32)
- âœ… éƒ½ä½¿ç”¨ FSDP åˆ†å¸ƒå¼è®­ç»ƒ
- âœ… éƒ½æ”¯æŒ Hydra é…ç½®è¦†ç›–

---

## ğŸ“š ç›¸å…³å‘½ä»¤å‚è€ƒ

### **å®Œæ•´è®­ç»ƒæµç¨‹å¯¹æ¯”**

#### ä½¿ç”¨ `finetune_lora.sh`
```bash
# 1. ç”Ÿæˆ SFT æ•°æ®ï¼ˆå¦‚æœéœ€è¦ï¼‰
python -m ragen.env.sokoban.create_dataset

# 2. è®­ç»ƒ
bash sft/finetune_lora.sh sokoban 4 ./sft_output

# 3. æ‰‹åŠ¨åˆå¹¶ LoRA
python sft/utils/merge_lora.py \
    --base_model_name Qwen/Qwen2.5-0.5B \
    --lora_model_path ./sft_output/global_step_XXX \
    --output_path ./merged_model

# 4. ä½¿ç”¨åˆå¹¶åçš„æ¨¡å‹è¿›è¡Œ RL è®­ç»ƒ
bash train.sh sokoban \
    model.base_model=./merged_model \
    ...
```

#### ä½¿ç”¨ `finetune_lora_med.sh`
```bash
# 1. æ•°æ®å·²é¢„å¤„ç†å¥½ (data/MTMedDialog_sft_train.parquet)

# 2. ä¸€é”®è®­ç»ƒ+åˆå¹¶
bash sft/finetune_lora_med.sh 8 ./sft_checkpoints

# 3. ç›´æ¥ä½¿ç”¨åˆå¹¶åçš„æ¨¡å‹
# DoctorLLM-7B-SFT-1000-thinking/ å·²ç»å¯ä»¥ç”¨äº RL

# 4. RL è®­ç»ƒ
bash scripts_exp/doctor-agent-rl-dynamic.sh
```

---

**ç»“è®º**: `finetune_lora_med.sh` æ˜¯é’ˆå¯¹ DoctorAgent-RL ä¼˜åŒ–çš„ä¸“ç”¨è„šæœ¬ï¼Œ
è€Œ `finetune_lora.sh` æ˜¯é€šç”¨è„šæœ¬ï¼Œå¯ç”¨äºå¤šç§ç¯å¢ƒçš„å¿«é€Ÿå®éªŒã€‚