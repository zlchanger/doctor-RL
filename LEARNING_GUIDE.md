# DoctorAgent-RL å­¦ä¹ æŒ‡å—

> ç¯å¢ƒå®‰è£…å®Œæˆåçš„å¾ªåºæ¸è¿›å­¦ä¹ è·¯çº¿

---

## ğŸ“‹ å­¦ä¹ è·¯çº¿å›¾æ¦‚è§ˆ

```
ç¬¬ä¸€é˜¶æ®µ â†’ ç¬¬äºŒé˜¶æ®µ â†’ ç¬¬ä¸‰é˜¶æ®µ â†’ ç¬¬å››é˜¶æ®µ â†’ ç¬¬äº”é˜¶æ®µ
ç†è§£æ¶æ„    æ•°æ®æ¢ç´¢    SFTå®éªŒ    RLè®­ç»ƒ      æ·±å…¥æºç 
(1-2å¤©)     (0.5å¤©)    (1-2å¤©)    (2-3å¤©)     (æŒç»­)
```

---

## ğŸ¯ ç¬¬ä¸€é˜¶æ®µï¼šç†è§£é¡¹ç›®æ¶æ„ï¼ˆ1-2å¤©ï¼‰

### æ ¸å¿ƒæ¦‚å¿µ

è¿™æ˜¯ä¸€ä¸ª**å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ åŒ»ç–—å¯¹è¯ç³»ç»Ÿ**ï¼š

| ç»„ä»¶ | è§’è‰² | å®ç° |
|------|------|------|
| **Doctor Agent** | ç­–ç•¥æ¨¡å‹ï¼ˆå¾…è®­ç»ƒï¼‰ | Qwen2.5-7B-Instruct + LoRA/FSDP |
| **Patient Agent** | ç¯å¢ƒæ¨¡æ‹Ÿå™¨ï¼ˆå›ºå®šï¼‰ | Qwen2.5-7B-Instruct + vLLM |
| **RLç®—æ³•** | è®­ç»ƒæ–¹æ³• | GRPO (é»˜è®¤) / PPO / BRPO / APO |
| **å¥–åŠ±å‡½æ•°** | ä¼˜åŒ–ç›®æ ‡ | è¯Šæ–­å‡†ç¡®æ€§ + é—®è¯Šæ•ˆç‡ + é—®é¢˜è´¨é‡ |

### ç³»ç»Ÿæ¶æ„

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Ray åˆ†å¸ƒå¼åè°ƒå™¨    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚          â”‚          â”‚          â”‚          â”‚
   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”  â”‚
   â”‚Actor    â”‚ â”‚Critic â”‚ â”‚Rolloutâ”‚ â”‚Env LLM   â”‚  â”‚
   â”‚Worker   â”‚ â”‚Worker â”‚ â”‚Worker â”‚ â”‚Worker    â”‚  â”‚
   â”‚(FSDP)   â”‚ â”‚(PPO)  â”‚ â”‚       â”‚ â”‚(vLLM)    â”‚  â”‚
   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â”‚
        â”‚         â”‚          â”‚          â”‚          â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                    è®­ç»ƒå¾ªç¯æµç¨‹:
        1. Rollout: åŒ»ç”Ÿé—®è¯Šï¼ˆé‡‡æ ·åŠ¨ä½œï¼‰
        2. Patient: æ‚£è€…å›ç­”ï¼ˆç¯å¢ƒåé¦ˆï¼‰
        3. Reward: è®¡ç®—å¥–åŠ±ï¼ˆå‡†ç¡®æ€§+æ•ˆç‡ï¼‰
        4. Update: æ›´æ–°ç­–ç•¥ï¼ˆPPO/GRPOï¼‰
```

### ç›®å½•ç»“æ„é€ŸæŸ¥

```bash
DoctorAgent-RL/
â”œâ”€â”€ ragen/                      # ä¸»æ¡†æ¶ä»£ç 
â”‚   â”œâ”€â”€ env/
â”‚   â”‚   â””â”€â”€ medical_consultation/  # åŒ»ç–—å¯¹è¯ç¯å¢ƒ
â”‚   â”‚       â”œâ”€â”€ env_patient_llm.py      # æ ¸å¿ƒç¯å¢ƒå®ç°
â”‚   â”‚       â”œâ”€â”€ env_patient_llm_rm.py   # å¸¦å¥–åŠ±æ¨¡å‹ç‰ˆæœ¬
â”‚   â”‚       â””â”€â”€ evaluation/             # è¯„ä¼°è„šæœ¬
â”‚   â”œâ”€â”€ trainer/
â”‚   â”‚   â”œâ”€â”€ main_ppo.py         # è®­ç»ƒå…¥å£
â”‚   â”‚   â””â”€â”€ ppo/ray_trainer.py  # Rayåˆ†å¸ƒå¼è®­ç»ƒå™¨
â”‚   â”œâ”€â”€ workers/                # åˆ†å¸ƒå¼Worker
â”‚   â””â”€â”€ utils/                  # å·¥å…·å‡½æ•°
â”œâ”€â”€ verl/                       # veRLå­æ¨¡å—ï¼ˆRLåŸºç¡€è®¾æ–½ï¼‰
â”œâ”€â”€ config/                     # Hydraé…ç½®æ–‡ä»¶
â”œâ”€â”€ scripts_exp/                # å®éªŒè®­ç»ƒè„šæœ¬
â”‚   â”œâ”€â”€ doctor-agent-rl-dynamic.sh           # æ¨èï¼šåŠ¨æ€è½®æ¬¡+SFT
â”‚   â”œâ”€â”€ doctor-agent-rl-rm-dynamic.sh        # å¸¦å¥–åŠ±æ¨¡å‹
â”‚   â””â”€â”€ ...
â”œâ”€â”€ sft/                        # ç›‘ç£å¾®è°ƒ
â”‚   â”œâ”€â”€ finetune_lora_med.sh    # LoRAè®­ç»ƒè„šæœ¬
â”‚   â””â”€â”€ utils/merge_lora.py     # æƒé‡åˆå¹¶
â””â”€â”€ data/                       # æ•°æ®é›†
    â”œâ”€â”€ MTMedDialog_RL.parquet          # RLè®­ç»ƒæ•°æ®
    â”œâ”€â”€ MTMedDialog_sft_train.parquet   # SFTè®­ç»ƒæ•°æ®
    â””â”€â”€ MTMedDialog_test.json           # æµ‹è¯•æ•°æ®
```

### å¿…è¯»æ–‡ä»¶æ¸…å•

```bash
# 1. é¡¹ç›®è¯´æ˜
cat README.md
cat README_RAGEN.md
cat CLAUDE.md

# 2. æ ¸å¿ƒç¯å¢ƒå®ç°ï¼ˆé‡ç‚¹ï¼‰
less ragen/env/medical_consultation/env_patient_llm.py

# 3. è®­ç»ƒè„šæœ¬ï¼ˆæŸ¥çœ‹å‚æ•°é…ç½®ï¼‰
cat scripts_exp/doctor-agent-rl-dynamic.sh

# 4. é…ç½®æ–‡ä»¶
cat config/base.yaml
```

---

## ğŸ” ç¬¬äºŒé˜¶æ®µï¼šæ•°æ®æ¢ç´¢ï¼ˆ0.5å¤©ï¼‰

### å¿«é€ŸæŸ¥çœ‹æ•°æ®

```bash
# åˆ›å»ºæ•°æ®æ¢ç´¢è„šæœ¬
cat > explore_data.py << 'EOF'
import pandas as pd
import json

print("=" * 60)
print("1. RLè®­ç»ƒæ•°æ® (MTMedDialog_RL.parquet)")
print("=" * 60)
rl_df = pd.read_parquet('data/MTMedDialog_RL.parquet')
print(f"æ ·æœ¬æ•°é‡: {len(rl_df)}")
print(f"åˆ—å: {rl_df.columns.tolist()}\n")

# æŸ¥çœ‹ç¬¬ä¸€æ¡æ ·æœ¬
sample = rl_df.iloc[0]
print("ç¤ºä¾‹æ ·æœ¬ç»“æ„:")
print(f"  - reward_model: {type(sample['reward_model'])}")
print(f"    - ground_truth (è¯Šæ–­æ ‡ç­¾): {sample['reward_model']['ground_truth']}")
print(f"    - patient_information (æœ‰æ•ˆé—®ç­”): {len(sample['reward_model']['patient_information'])} æ¡")
print(f"    - enhanced_description (æ‚£è€…æè¿°):")
print(f"      {sample['reward_model']['enhanced_description'][:200]}...\n")

print("=" * 60)
print("2. SFTè®­ç»ƒæ•°æ® (MTMedDialog_sft_train.parquet)")
print("=" * 60)
sft_df = pd.read_parquet('data/MTMedDialog_sft_train.parquet')
print(f"æ ·æœ¬æ•°é‡: {len(sft_df)}")
print(f"åˆ—å: {sft_df.columns.tolist()}\n")

sample_sft = sft_df.iloc[0]
print("ç¤ºä¾‹å¯¹è¯æ ¼å¼:")
print(f"Prompt:\n{sample_sft['prompt'][:150]}...\n")
print(f"Response (å¸¦<think>æ ‡ç­¾):\n{sample_sft['response'][:300]}...\n")

print("=" * 60)
print("3. æµ‹è¯•æ•°æ® (MTMedDialog_test.json)")
print("=" * 60)
with open('data/MTMedDialog_test.json') as f:
    test_data = json.load(f)
print(f"æµ‹è¯•æ ·æœ¬æ•°: {len(test_data)}")
print(f"ç¬¬ä¸€æ¡é”®å: {list(test_data[0].keys())}")
EOF

python explore_data.py
```

### æ•°æ®æ ¼å¼è¯´æ˜

#### RLè®­ç»ƒæ•°æ®æ ¼å¼

```python
{
    'reward_model': {
        'ground_truth': 'ç³–å°¿ç—…',  # æ­£ç¡®è¯Šæ–­æ ‡ç­¾
        'patient_information': [   # æœ‰æ•ˆçš„é—®ç­”å¯¹
            {
                'doctor_question': 'æ‚¨å¤šä¹…å‰å‡ºç°è¿™äº›ç—‡çŠ¶çš„ï¼Ÿ',
                'patient_response': 'å¤§çº¦ä¸‰ä¸ªæœˆå‰å¼€å§‹çš„'
            },
            # ... æ›´å¤šé—®ç­”
        ],
        'enhanced_description': 'æ‚£è€…ä¸»è¯‰ï¼šæˆ‘æœ€è¿‘æ€»æ˜¯æ„Ÿåˆ°å£æ¸´...'  # ç”¨äºLLMæ¨¡æ‹Ÿ
    },
    'extra_info': {
        'index': 12345  # ç”¨ä½œç¯å¢ƒseed
    }
}
```

#### SFTæ•°æ®æ ¼å¼

```python
{
    'prompt': 'æ‚£è€…ä¸»è¯‰ï¼šæˆ‘æœ€è¿‘æ€»æ˜¯æ„Ÿåˆ°å£æ¸´ï¼Œè¿˜ç»å¸¸ä¸Šå•æ‰€...',
    'response': '<think>æ‚£è€…å‡ºç°å¤šé¥®å¤šå°¿ç—‡çŠ¶ï¼Œéœ€è¦è¯¢é—®...</think><answer>æ‚¨å¥½ï¼Œè¯·é—®æ‚¨è¿™äº›ç—‡çŠ¶æŒç»­å¤šä¹…äº†ï¼Ÿ</answer>'
}
```

**å…³é”®ç‚¹**ï¼š
- `<think>...</think>` æ ‡ç­¾ï¼šå†…éƒ¨æ¨ç†è¿‡ç¨‹
- `<answer>...</answer>` æ ‡ç­¾ï¼šå®é™…è¾“å‡ºï¼ˆé—®é¢˜/è¯Šæ–­ï¼‰

---

## ğŸ§ª ç¬¬ä¸‰é˜¶æ®µï¼šSFTè®­ç»ƒå®éªŒï¼ˆ1-2å¤©ï¼‰

### ä¸ºä»€ä¹ˆå…ˆåšSFTï¼Ÿ

SFTï¼ˆç›‘ç£å¾®è°ƒï¼‰æä¾›äº†**å†·å¯åŠ¨**ï¼Œè®©æ¨¡å‹å­¦ä¼šåŸºæœ¬çš„åŒ»ç–—å¯¹è¯æ ¼å¼å’Œæ¨ç†æ¨¡å¼ï¼Œé¿å…RLä»é›¶å¼€å§‹è®­ç»ƒã€‚

### å‡†å¤‡å·¥ä½œ

```bash
# 1. ä¸‹è½½åŸºç¡€æ¨¡å‹ï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰
# æ–¹å¼1ï¼šä½¿ç”¨ HuggingFace CLI
pip install huggingface_hub
huggingface-cli login  # è¾“å…¥ä½ çš„token
huggingface-cli download Qwen/Qwen2.5-7B-Instruct --local-dir ./models/Qwen2.5-7B-Instruct

# æ–¹å¼2ï¼šåœ¨Pythonä¸­è‡ªåŠ¨ä¸‹è½½ï¼ˆé¦–æ¬¡è®­ç»ƒæ—¶ä¼šè‡ªåŠ¨ä¸‹è½½ï¼‰
```

### å¿«é€Ÿæµ‹è¯•è®­ç»ƒï¼ˆå°è§„æ¨¡ï¼‰

```bash
# 1. åˆ›å»ºæµ‹è¯•é…ç½®ï¼ˆä¿®æ”¹å‚æ•°ä»¥åŠ å¿«è®­ç»ƒï¼‰
cp sft/finetune_lora_med.sh sft/finetune_lora_test.sh

# 2. ç¼–è¾‘ sft/finetune_lora_test.shï¼Œä¿®æ”¹ä»¥ä¸‹å‚æ•°ï¼š
#    --max_steps 100                    # ä»1000æ”¹ä¸º100
#    --learning_rate 5e-5               # å¯ä»¥æé«˜å­¦ä¹ ç‡åŠ å¿«æ”¶æ•›
#    --per_device_train_batch_size 4    # æ ¹æ®æ˜¾å­˜è°ƒæ•´
#    --gradient_accumulation_steps 2

# 3. è¿è¡Œæµ‹è¯•è®­ç»ƒï¼ˆå•GPUï¼‰
bash sft/finetune_lora_test.sh 1 ./test_sft_checkpoint

# 4. è§‚å¯Ÿè®­ç»ƒæ—¥å¿—
# æ³¨æ„ï¼š
#   - è®­ç»ƒlossåº”é€æ­¥ä¸‹é™
#   - å…³æ³¨ 'train/loss' æŒ‡æ ‡
#   - å¦‚æœä½¿ç”¨ wandbï¼Œå¯ä»¥åœ¨ç½‘é¡µæŸ¥çœ‹æ›²çº¿
```

### å®Œæ•´SFTè®­ç»ƒ

```bash
# ä½¿ç”¨8ä¸ªGPUè¿›è¡Œå®Œæ•´è®­ç»ƒï¼ˆéœ€è¦çº¦2å°æ—¶ï¼‰
bash sft/finetune_lora_med.sh 8 ./sft_checkpoints

# è®­ç»ƒå®Œæˆååˆå¹¶LoRAæƒé‡
python sft/utils/merge_lora.py \
    --base_model_name Qwen/Qwen2.5-7B-Instruct \
    --lora_model_path ./sft_checkpoints \
    --output_path ./DoctorLLM-7B-SFT-Custom
```

### SFTé˜¶æ®µçš„å­¦ä¹ é‡ç‚¹

1. **LoRAæŠ€æœ¯**ï¼šç†è§£ä½ç§©é€‚åº”å¦‚ä½•å‡å°‘è®­ç»ƒå‚æ•°
2. **Promptæ ¼å¼**ï¼šå­¦ä¹  `<think><answer>` çš„ä½¿ç”¨
3. **è¯„ä¼°æŒ‡æ ‡**ï¼šè§‚å¯Ÿè®­ç»ƒlosså’ŒéªŒè¯loss
4. **è¶…å‚æ•°è°ƒæ•´**ï¼šå­¦ä¹ ç‡ã€batch sizeçš„å½±å“

---

## ğŸš€ ç¬¬å››é˜¶æ®µï¼šRLè®­ç»ƒå®éªŒï¼ˆ2-3å¤©ï¼‰

### ç†è§£RLè®­ç»ƒæµç¨‹

```
å¾ªç¯è¿­ä»£:
  for æ¯ä¸ªè®­ç»ƒæ‰¹æ¬¡:
    1. [Rollout] Doctorå‘èµ·é—®è¯Šå¯¹è¯
       - è¾“å…¥: æ‚£è€…åˆå§‹æè¿°
       - è¾“å‡º: ç”Ÿæˆé—®é¢˜ï¼ˆé‡‡æ ·å¤šä¸ªå“åº”ç”¨äºGRPOï¼‰

    2. [Environment] Patient LLMå“åº”
       - ä½¿ç”¨vLLMè¿›è¡Œå¿«é€Ÿæ¨ç†
       - è¿”å›æ‚£è€…å›ç­”

    3. [Multi-turn] å¾ªç¯é—®ç­”ï¼ˆ2-10è½®ï¼‰
       - Doctorç»§ç»­æé—®æˆ–ç»™å‡ºè¯Šæ–­
       - Patientç»§ç»­å›ç­”

    4. [Reward] è®¡ç®—å¥–åŠ±
       - è¯Šæ–­å‡†ç¡®æ€§ï¼ˆä¸»è¦å¥–åŠ±ï¼‰
       - é—®é¢˜æœ‰æ•ˆæ€§ï¼ˆæ˜¯å¦åœ¨patient_informationä¸­ï¼‰
       - å¯¹è¯æ•ˆç‡ï¼ˆè½®æ¬¡æƒ©ç½šï¼‰

    5. [Policy Update] æ›´æ–°ç­–ç•¥
       - GRPO: ç»„å†…å½’ä¸€åŒ–ä¼˜åŠ¿å‡½æ•°
       - PPO: ä½¿ç”¨Criticä¼°è®¡value
       - ä¼˜åŒ–ç­–ç•¥ä»¥æœ€å¤§åŒ–ç´¯ç§¯å¥–åŠ±
```

### å°è§„æ¨¡æµ‹è¯•ï¼ˆæ¨èé¦–æ¬¡è¿è¡Œï¼‰

```bash
# 1. åˆ›å»ºæµ‹è¯•è„šæœ¬ï¼ˆå‡å°‘æ•°æ®é‡å’Œè¿­ä»£æ¬¡æ•°ï¼‰
cat > scripts_exp/test_rl_training.sh << 'EOF'
#!/bin/bash

export CUDA_VISIBLE_DEVICES=0,1,2,3  # ä½¿ç”¨4ä¸ªGPU
export VLLM_ATTENTION_BACKEND=XFORMERS

python -m ragen.trainer.main_ppo \
    data.train_files=data/MTMedDialog_RL.parquet \
    data.train_batch_size=4 \
    actor_rollout_ref.rollout.n_agent=4 \
    actor_rollout_ref.actor.ppo_mini_batch_size=4 \
    actor_rollout_ref.actor.ppo_micro_batch_size=1 \
    actor_rollout_ref.model.path=Qwen/Qwen2.5-7B-Instruct \
    algorithm.adv_estimator=grpo \
    env=medical_consultation \
    env.max_turns=-1 \
    training.total_training_steps=10 \
    training.save_freq=5 \
    project_name=doctor-agent-test \
    experiment_name=quick-test
EOF

bash scripts_exp/test_rl_training.sh
```

### å®Œæ•´è®­ç»ƒï¼ˆä½¿ç”¨SFTå†·å¯åŠ¨ï¼‰

```bash
# æ¨èï¼šåŠ¨æ€è½®æ¬¡ + SFTåˆå§‹åŒ–
bash scripts_exp/doctor-agent-rl-dynamic.sh

# å…³é”®å‚æ•°è¯´æ˜ï¼š
# - actor_rollout_ref.model.path: ä½¿ç”¨ä½ çš„SFTæ¨¡å‹è·¯å¾„
# - env.max_turns=-1: æ¯ä¸ªepisodeéšæœºé€‰æ‹©2-10è½®å¯¹è¯
# - algorithm.adv_estimator=grpo: ä½¿ç”¨Group Relative Policy Optimization
# - training.total_training_steps=500: æ€»è®­ç»ƒæ­¥æ•°
```

### ç›‘æ§è®­ç»ƒè¿›åº¦

```bash
# 1. ä½¿ç”¨ WandB åœ¨çº¿ç›‘æ§ï¼ˆæ¨èï¼‰
export WANDB_API_KEY=your_key_here
# è®­ç»ƒæ—¶ä¼šè‡ªåŠ¨ä¸Šä¼ æŒ‡æ ‡åˆ° wandb.ai

# 2. æŸ¥çœ‹æœ¬åœ°æ—¥å¿—
tail -f logs/train.log  # å¦‚æœæœ‰æ—¥å¿—æ–‡ä»¶

# 3. æ£€æŸ¥checkpoint
ls -lh checkpoints/doctor-agent/exp_name/
```

### é‡è¦æŒ‡æ ‡

| æŒ‡æ ‡åç§° | å«ä¹‰ | æœŸæœ›è¶‹åŠ¿ |
|---------|------|---------|
| `reward/mean` | å¹³å‡å¥–åŠ± | ä¸Šå‡ |
| `reward/diagnosis_correct_rate` | è¯Šæ–­å‡†ç¡®ç‡ | ä¸Šå‡ |
| `metrics/valid_action_rate` | æœ‰æ•ˆé—®é¢˜å æ¯” | ä¸Šå‡ |
| `metrics/avg_turns` | å¹³å‡å¯¹è¯è½®æ¬¡ | ä¸‹é™ï¼ˆæ›´é«˜æ•ˆï¼‰ |
| `policy/kl_divergence` | KLæ•£åº¦ | ç¨³å®šåœ¨åˆç†èŒƒå›´ |
| `policy/loss` | ç­–ç•¥æŸå¤± | ä¸‹é™åç¨³å®š |

### RLè®­ç»ƒçš„å­¦ä¹ é‡ç‚¹

1. **GRPO vs PPO**ï¼šç†è§£ä¸åŒç®—æ³•çš„ä¼˜åŠ¿
2. **å¥–åŠ±è®¾è®¡**ï¼šè¯Šæ–­å‡†ç¡®æ€§å¦‚ä½•å¹³è¡¡å¯¹è¯æ•ˆç‡
3. **æ¢ç´¢ä¸åˆ©ç”¨**ï¼štemperatureå‚æ•°çš„ä½œç”¨
4. **åˆ†å¸ƒå¼è®­ç»ƒ**ï¼šRayå¦‚ä½•åè°ƒå¤šä¸ªworker

---

## ğŸ¯ ç¬¬äº”é˜¶æ®µï¼šæ¨¡å‹è¯„ä¼°ï¼ˆ1å¤©ï¼‰

### è¯„ä¼°æµç¨‹

```bash
# 1. ç¡®ä¿æ¨¡å‹å·²åˆå¹¶ï¼ˆè®­ç»ƒè„šæœ¬é€šå¸¸ä¼šè‡ªåŠ¨å®Œæˆï¼‰
ls ./checkpoints/your_model/

# 2. è¿è¡Œè¯„ä¼°ï¼ˆæœ¬åœ°æ¨¡å‹ï¼‰
bash ragen/env/medical_consultation/evaluation/run_eval_patientllm_category.sh \
    ./checkpoints/your_model

# 3. æŸ¥çœ‹ç»“æœ
cat results_patientllm_category_*.json
```

### è¯„ä¼°æŒ‡æ ‡è§£è¯»

```json
{
    "overall": {
        "accuracy": 0.75,           // è¯Šæ–­å‡†ç¡®ç‡
        "avg_turns": 4.2,           // å¹³å‡å¯¹è¯è½®æ¬¡
        "invalid_rate": 0.05        // æ— æ•ˆé—®é¢˜æ¯”ä¾‹
    },
    "by_category": {
        "ç³–å°¿ç—…": {
            "accuracy": 0.82,
            "samples": 50
        },
        // ... å„ç–¾ç—…ç±»åˆ«çš„è¡¨ç°
    }
}
```

### å¯¹æ¯”åŸºçº¿

```bash
# è¯„ä¼°åŸºç¡€æ¨¡å‹ï¼ˆæœªç»RLè®­ç»ƒï¼‰
bash ragen/env/medical_consultation/evaluation/run_eval_patientllm_category.sh \
    Qwen/Qwen2.5-7B-Instruct

# è¯„ä¼°SFTæ¨¡å‹
bash ragen/env/medical_consultation/evaluation/run_eval_patientllm_category.sh \
    ./DoctorLLM-7B-SFT-Custom

# å¯¹æ¯”ä¸‰è€…æ€§èƒ½æå‡
```

---

## ğŸ“š ç¬¬å…­é˜¶æ®µï¼šæ·±å…¥æºç ç†è§£ï¼ˆæŒç»­å­¦ä¹ ï¼‰

### æ ¸å¿ƒä»£ç é˜…è¯»è·¯å¾„

#### 1. ç¯å¢ƒå®ç° (æœ€é‡è¦)

```bash
# é˜…è¯»é¡ºåºï¼š
# 1. åŸºç±»å®šä¹‰
ragen/env/base.py

# 2. åŒ»ç–—å¯¹è¯ç¯å¢ƒ
ragen/env/medical_consultation/env_patient_llm.py
#   é‡ç‚¹æ–¹æ³•ï¼š
#   - reset(): åˆå§‹åŒ–episode
#   - step(): å¤„ç†åŠ¨ä½œï¼Œè®¡ç®—å¥–åŠ±
#   - _extract_answer(): è§£æ<answer>æ ‡ç­¾
#   - _calculate_reward(): å¥–åŠ±è®¡ç®—é€»è¾‘

# 3. å¸¦å¥–åŠ±æ¨¡å‹çš„ç‰ˆæœ¬
ragen/env/medical_consultation/env_patient_llm_rm.py
```

#### 2. è®­ç»ƒæµç¨‹

```bash
# 1. è®­ç»ƒå…¥å£
ragen/trainer/main_ppo.py
#   - Hydraé…ç½®åŠ è½½
#   - Rayé›†ç¾¤åˆå§‹åŒ–
#   - è°ƒç”¨ ray_trainer

# 2. Rayåˆ†å¸ƒå¼è®­ç»ƒå™¨
ragen/trainer/ppo/ray_trainer.py
#   - Actor/Critic/Rollout/EnvLLM workerç®¡ç†
#   - è®­ç»ƒå¾ªç¯orchestration
```

#### 3. Workerå®ç°

```bash
# ç¯å¢ƒLLM Workerï¼ˆæ‚£è€…æ¨¡æ‹Ÿï¼‰
ragen/workers/env_llm_worker.py
#   - vLLMæ¨ç†å°è£…
#   - æ‰¹é‡ç”Ÿæˆæ‚£è€…å›ç­”

# Actor Workerï¼ˆç­–ç•¥æ¨¡å‹ï¼‰
ragen/workers/actor_worker.py
#   - FSDPæ¨¡å‹ç®¡ç†
#   - PPOæ›´æ–°é€»è¾‘
```

### è°ƒè¯•æŠ€å·§

```bash
# 1. æ‰“å°è°ƒè¯•ä¿¡æ¯
export RAY_DEBUG_POST_MORTEM=1  # Rayè¯¦ç»†é”™è¯¯ä¿¡æ¯
export CUDA_LAUNCH_BLOCKING=1   # CUDAåŒæ­¥æ‰§è¡Œ

# 2. å•æ­¥è°ƒè¯•
# åœ¨ä»£ç ä¸­æ·»åŠ ï¼š
import pdb; pdb.set_trace()

# 3. æ—¥å¿—çº§åˆ«
export LOGLEVEL=DEBUG
```

### ä»£ç ä¿®æ”¹å®éªŒå»ºè®®

1. **ä¿®æ”¹å¥–åŠ±å‡½æ•°**
   - æ–‡ä»¶ï¼š`ragen/env/medical_consultation/env_patient_llm.py`
   - æ–¹æ³•ï¼š`_calculate_reward()`
   - å®éªŒï¼šå°è¯•ä¸åŒçš„å¥–åŠ±æƒé‡ç»„åˆ

2. **è°ƒæ•´max_turnsç­–ç•¥**
   - å®éªŒï¼šå›ºå®šè½®æ¬¡ vs åŠ¨æ€è½®æ¬¡çš„å½±å“

3. **æ”¹å˜GRPOå®ç°**
   - æ–‡ä»¶ï¼šç›¸å…³ç®—æ³•å®ç°
   - å®éªŒï¼šå¯¹æ¯”GRPO/PPO/BRPOçš„æ”¶æ•›é€Ÿåº¦

---

## ğŸ› ï¸ å¸¸è§é—®é¢˜ä¸è§£å†³

### Q1: CUDAå†…å­˜ä¸è¶³

```bash
# è§£å†³æ–¹æ¡ˆï¼š
# 1. å‡å°batch size
data.train_batch_size=2
actor_rollout_ref.actor.ppo_mini_batch_size=2

# 2. ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯
actor_rollout_ref.actor.gradient_accumulation_steps=4

# 3. å¯ç”¨FSDP
actor_rollout_ref.actor.fsdp_config.enable=true
```

### Q2: Rayåˆå§‹åŒ–å¤±è´¥

```bash
# æ¸…ç†Rayè¿›ç¨‹
ray stop --force

# é‡å¯è®­ç»ƒ
```

### Q3: vLLMåŠ è½½å¤±è´¥

```bash
# æ£€æŸ¥æ¨¡å‹è·¯å¾„
ls -l path/to/model/

# ç¡®è®¤ç¯å¢ƒå˜é‡
export VLLM_ATTENTION_BACKEND=XFORMERS
```

### Q4: è®­ç»ƒä¸æ”¶æ•›

```bash
# è°ƒè¯•æ­¥éª¤ï¼š
# 1. æ£€æŸ¥å¥–åŠ±æ˜¯å¦åˆç†ï¼ˆä¸åº”ä¸ºå¸¸æ•°ï¼‰
# 2. é™ä½å­¦ä¹ ç‡
actor_rollout_ref.actor.optim.lr=1e-7

# 3. å¢åŠ KLç³»æ•°ï¼ˆå‡å°‘åç¦»å‚è€ƒæ¨¡å‹ï¼‰
algorithm.kl_ctrl.kl_coef=0.1

# 4. ä½¿ç”¨SFTå†·å¯åŠ¨ï¼ˆè€Œééšæœºåˆå§‹åŒ–ï¼‰
```

---

## ğŸ“ˆ å­¦ä¹ è¿›åº¦æ£€æŸ¥æ¸…å•

### åŸºç¡€ç†è§£ (å®Œæˆåå¯è¿›å…¥å®è·µ)
- [ ] ç†è§£Doctor/Patientä¸¤ä¸ªAgentçš„è§’è‰²
- [ ] ç†è§£GRPO/PPOçš„åŸºæœ¬åŸç†
- [ ] ç†Ÿæ‚‰é¡¹ç›®ç›®å½•ç»“æ„
- [ ] ç†è§£æ•°æ®æ ¼å¼ï¼ˆRLå’ŒSFTï¼‰

### å®è·µæ“ä½œ (å®Œæˆåå¯æ·±å…¥ç ”ç©¶)
- [ ] æˆåŠŸè¿è¡Œæ•°æ®æ¢ç´¢è„šæœ¬
- [ ] å®Œæˆä¸€æ¬¡SFTè®­ç»ƒï¼ˆå°è§„æ¨¡å³å¯ï¼‰
- [ ] å®Œæˆä¸€æ¬¡RLè®­ç»ƒï¼ˆå°è§„æ¨¡å³å¯ï¼‰
- [ ] è¿è¡Œæ¨¡å‹è¯„ä¼°å¹¶ç†è§£æŒ‡æ ‡

### æ·±å…¥ç ”ç©¶ (è¿›é˜¶ç›®æ ‡)
- [ ] é˜…è¯»å¹¶ç†è§£ç¯å¢ƒå®ç°ä»£ç 
- [ ] ä¿®æ”¹å¥–åŠ±å‡½æ•°å¹¶è§‚å¯Ÿå½±å“
- [ ] å¯¹æ¯”ä¸åŒRLç®—æ³•çš„æ•ˆæœ
- [ ] å°è¯•åœ¨æ–°æ•°æ®é›†ä¸Šè®­ç»ƒ

---

## ğŸ“ æ¨èå­¦ä¹ èµ„æº

### è®ºæ–‡é˜…è¯»

1. **DoctorAgent-RLåŸè®ºæ–‡**
   - https://arxiv.org/pdf/2505.19630

2. **GRPOç®—æ³•**
   - Group Relative Policy Optimization (GRPO) ç›¸å…³è®ºæ–‡

3. **RLHFåŸºç¡€**
   - "Training language models to follow instructions with human feedback" (InstructGPT)

### ç›¸å…³æ–‡æ¡£

```bash
# RAGENæ¡†æ¶æ–‡æ¡£
https://ragen-tutorial.readthedocs.io/

# veRLæ–‡æ¡£
https://verl.readthedocs.io/

# Qwen2.5æ¨¡å‹æ–‡æ¡£
https://github.com/QwenLM/Qwen2.5
```

### ç¤¾åŒºèµ„æº

- GitHub Issues: æŸ¥çœ‹å…¶ä»–ç”¨æˆ·çš„é—®é¢˜
- Discussions: å‚ä¸æŠ€æœ¯è®¨è®º

---

## ğŸ’¡ å­¦ä¹ å»ºè®®

1. **å¾ªåºæ¸è¿›**ï¼šä¸è¦è·³è¿‡å‰é¢çš„é˜¶æ®µï¼Œç¡®ä¿ç†è§£æ¯ä¸ªæ¦‚å¿µ
2. **å®è·µä¸ºä¸»**ï¼šå…ˆè¿è¡Œä»£ç ï¼Œå†æ·±å…¥ç†è§£åŸç†
3. **è®°å½•å®éªŒ**ï¼šæ¯æ¬¡è®­ç»ƒè®°å½•é…ç½®å’Œç»“æœï¼Œä¾¿äºå¯¹æ¯”
4. **ä¿®æ”¹å°è¯•**ï¼šä¸è¦æ€•æ”¹ä»£ç ï¼Œé€šè¿‡ä¿®æ”¹åŠ æ·±ç†è§£
5. **æŸ¥é˜…æ–‡æ¡£**ï¼šé‡åˆ°é—®é¢˜å…ˆçœ‹READMEå’Œæºç æ³¨é‡Š

---

## ğŸ“ è·å–å¸®åŠ©

1. **æŸ¥çœ‹æ—¥å¿—**ï¼šå¤§å¤šæ•°é—®é¢˜å¯ä»é”™è¯¯æ—¥å¿—æ‰¾åˆ°ç­”æ¡ˆ
2. **é˜…è¯»æºç **ï¼šä»£ç æ³¨é‡Šè¯¦ç»†ï¼Œå¯ç›´æ¥é˜…è¯»
3. **GitHub Issues**ï¼šæœç´¢æˆ–æäº¤æ–°é—®é¢˜
4. **è®ºæ–‡é™„å½•**ï¼šæŸ¥çœ‹å®éªŒç»†èŠ‚å’Œè¶…å‚æ•°è®¾ç½®

---

ç¥å­¦ä¹ é¡ºåˆ©ï¼ ğŸš€